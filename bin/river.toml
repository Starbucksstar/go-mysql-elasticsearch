# MySQL address, user and password
# user must have replication privilege in MySQL. 

my_addr = "prod-data-1.mysql.database.chinacloudapi.cn:3306"
my_user = "quzhe@prod-data-1"
my_pass = "TWr0ys1ngh4m"
my_charset = "utf8"

# Set true when elasticsearch use https
#es_https = false
# Elasticsearch address
es_addr = "host.docker.internal:9200"
# Elasticsearch user and password, maybe set by shield, nginx, or x-pack
es_user = ""
es_pass = ""

# Path to store data, like master.info, if not set or empty,
# we must use this to support breakpoint resume syncing. 
# TODO: support other storage, like etcd. 
data_dir = "./var"

# Inner Http status address
stat_addr = "127.0.0.1:12800"
stat_path = "/metrics"

# pseudo server id like a slave 
server_id = 1001

# mysql or mariadb
flavor = "mysql"

#connect mysql use ssl
use_ssl = true

#mysqldump use ssl
mysql_dump_use_ssl = "--ssl=1"

# mysqldump execution path
# if not set or empty, ignore mysqldump.
mysqldump = "mysqldump"

# if we have no privilege to use mysqldump with --master-data,
# we must skip it.
#skip_master_data = false

# minimal items to be inserted in one bulk
bulk_size = 128

# force flush the pending requests if we don't have enough items >= bulk_size
flush_bulk_time = "200ms"

# Ignore table without primary key
skip_no_pk_table = false

# MySQL data source
[[source]]
schema = "scene_dev"
tables = ["panorama"]

[[source]]
schema = "scene_dev"
tables = ["scene"]

[[rule]]
schema = "scene_dev"
table = "scene"
index = "scene"
type = "info"

[[rule]]
schema = "scene_dev"
table = "panorama"
index = "panorama"
type = "info"


